{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   1.   0. 100.]\n",
      " [  1.   0.   0.  60.]\n",
      " [  0.   0.   1.  30.]]\n",
      "--------------------------------------------------\n",
      "['city=上海' 'city=北京' 'city=深圳' 'temperature']\n",
      "--------------------------------------------------\n",
      "[{'city=北京': 1.0, 'temperature': 100.0}, {'city=上海': 1.0, 'temperature': 60.0}, {'city=深圳': 1.0, 'temperature': 30.0}]\n"
     ]
    }
   ],
   "source": [
    "def dictvec():\n",
    "    \"\"\"\n",
    "    字典数据提取\n",
    "    把字典中的类别提取为one-hot编码\n",
    "    \"\"\"\n",
    "    # sparse=True表示数据为稀疏矩阵\n",
    "    dict = DictVectorizer(sparse=False)\n",
    "\n",
    "    # 调用fit_transform\n",
    "    data = dict.fit_transform([{\"city\":\"北京\",\"temperature\":100},\n",
    "                               {\"city\":\"上海\",\"temperature\":60},\n",
    "                               {\"city\":\"深圳\",\"temperature\":30}])\n",
    "\n",
    "    print(data)\n",
    "    print(\"-\"*50)\n",
    "    # 返回特征的名称\n",
    "    print(dict.get_feature_names_out())\n",
    "    print(\"-\"*50)\n",
    "    print(dict.inverse_transform(data))\n",
    "\n",
    "dictvec()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is' 'life' 'python']\n",
      "  (0, 1)\t2\n",
      "  (0, 0)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 0)\t1\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[[1 2 1]\n",
      " [1 1 1]\n",
      " [1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "def countvec():\n",
    "    \"\"\"\n",
    "    文本特征抽取\n",
    "    \"\"\"\n",
    "    # max_df min_df 该词的词频不小于最小值min_df，小于等于max_df\n",
    "    vector = CountVectorizer(min_df=2)\n",
    "    # 调用fit_transform输入并转换数据\n",
    "\n",
    "    res = vector.fit_transform(\n",
    "        [\"life is shor,i like python life\",\n",
    "         \"life is too long,i dislike python\",\n",
    "         \"life is short\"])\n",
    "\n",
    "    # 将每个词都分离了，并且统计了词频\n",
    "    print(vector.get_feature_names_out())\n",
    "    print(res)\n",
    "    print(type(res))\n",
    "    print(res.toarray())\n",
    "\n",
    "countvec()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python' '不用' '人生漫长' '人生苦短' '喜欢']\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 0)\t2\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 1)\t1\n",
      "[[2 0 0 1 1]\n",
      " [1 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def countChineseVec():\n",
    "    vec = CountVectorizer()\n",
    "\n",
    "    data = vec.fit_transform([\"人生苦短，我 喜欢 python python\",\"人生漫长，我 不用 python\"])\n",
    "\n",
    "    print(vec.get_feature_names_out())\n",
    "\n",
    "    print(data)\n",
    "    print(data.toarray())\n",
    "\n",
    "    return None\n",
    "\n",
    "countChineseVec()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tf-idf主要思想 如果某个词或者短语在一篇文章中出现的频率高，并且在其他文章中很少出现，则可以认为这个词或者短语具有很好的分类能力\n",
    "### tf-idf主要用来评估一个词对于一个文件集或者一个语料库中的其中一份文件的重要程度\n",
    "Tf: 词的频率\n",
    "idf: 逆文档频率\n",
    "log: 总文档数量/该词出现的文档数量\n",
    "tf*idf来代表重要性中程度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03896104 0.         0.         0.        ]\n",
      " [1.         1.         1.         0.83333333]\n",
      " [0.         0.5        0.6        1.        ]]\n"
     ]
    }
   ],
   "source": [
    "def minMaxStand():\n",
    "    \"\"\"\n",
    "    归一化处理\n",
    "    \"\"\"\n",
    "    # 归一化容易受极端值的影响\n",
    "    mm = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "    data = [[90,2,10,40],[460,4,15,45],[75,3,13,46]]\n",
    "    res = mm.fit_transform(data)\n",
    "\n",
    "    print(res)\n",
    "    return None\n",
    "\n",
    "minMaxStand()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.66456798 -1.22474487 -1.29777137 -1.3970014 ]\n",
      " [ 1.41337698  1.22474487  1.13554995  0.50800051]\n",
      " [-0.748809    0.          0.16222142  0.88900089]]\n",
      "均值为: [208.33333333   3.          12.66666667  43.66666667]\n",
      "方差为: [3.17055556e+04 6.66666667e-01 4.22222222e+00 6.88888889e+00]\n",
      "样本数: 3\n"
     ]
    }
   ],
   "source": [
    "def standerScale():\n",
    "    \"\"\"\n",
    "    正太标准化\n",
    "    \"\"\"\n",
    "\n",
    "    std = StandardScaler()\n",
    "\n",
    "    data = [[90,2,10,40],[460,4,15,45],[75,3,13,46]]\n",
    "\n",
    "    res = std.fit_transform(data)\n",
    "\n",
    "    print(res)\n",
    "    print(\"均值为:\",std.mean_)\n",
    "    print(\"方差为:\",std.var_)\n",
    "    print(\"样本数:\",std.n_samples_seen_)\n",
    "\n",
    "standerScale()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 标准化和归一化\n",
    "对于归一化来说，如果出现了异常点，影响了最大值和最小值，那么结果会发送改变\n",
    "对于标准化来说，如果出现了异常点，由于具有一定的数据量，异常点对于平均值的影响不大，所以方差改变较小"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [4. 3.]\n",
      " [7. 6.]]\n"
     ]
    }
   ],
   "source": [
    "def im():\n",
    "    \"\"\"\n",
    "    缺失值处理\n",
    "    \"\"\"\n",
    "    # 缺失值必须是NaN nan这种形式，如果是?那么需要replace\n",
    "    im = SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "\n",
    "    data = [[1,2],[np.nan,3],[7,6]]\n",
    "    res = im.fit_transform(data)\n",
    "\n",
    "    print(res)\n",
    "    return None\n",
    "\n",
    "im()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 特征选择\n",
    "+ Filter过滤式:VarianceThreshold\n",
    "+ Embedded嵌入式:正则化、决策树\n",
    "+ Wrapper包裹式"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0]\n",
      " [1 4]\n",
      " [1 1]]\n",
      "The support is [1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def var():\n",
    "    \"\"\"\n",
    "    特征选择：删除低方差的特征\n",
    "    \"\"\"\n",
    "    var = VarianceThreshold(threshold=0)\n",
    "\n",
    "    data = [[0,2,0,3],[0,1,4,3],[0,1,1,3]]\n",
    "\n",
    "    res = var.fit_transform(data)\n",
    "\n",
    "    print(res)\n",
    "    # 获得剩余特征的列编号\n",
    "    print(f\"The support is %s\" % var.get_support(True))\n",
    "\n",
    "    return None\n",
    "\n",
    "var()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.76504522]\n",
      " [ 2.35339362]\n",
      " [-0.58834841]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca():\n",
    "    \"\"\"\n",
    "    主成分分析进行特征降维\n",
    "    n_components参数 小数为百分比  整数为降维后特征个数\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=0.9)\n",
    "\n",
    "    data = [[0,2,0,3],[0,1,4,3],[0,1,1,3]]\n",
    "    res = pca.fit_transform(data)\n",
    "\n",
    "    print(res)\n",
    "    return None\n",
    "\n",
    "pca()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}